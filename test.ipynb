{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# set UPSTAGE_API_KEY in .env file\n",
    "# UPSTAGE_API_KEY=your_api_key\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, \n",
    "demonstrating superior performance in various natural language processing (NLP) tasks. \n",
    "Inspired by recent efforts to efficiently up-scale LLMs, \n",
    "we present a method for scaling LLMs called depth up-scaling (DUS), \n",
    "which encompasses depthwise scaling and continued pretraining.\n",
    "In contrast to other LLM up-scaling methods that use mixture-of-experts, \n",
    "DUS does not require complex changes to train and inference efficiently. \n",
    "We show experimentally that DUS is simple yet effective \n",
    "in scaling up high-performance LLMs from small ones. \n",
    "Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, \n",
    "a variant fine-tuned for instruction-following capabilities, \n",
    "surpassing Mixtral-8x7B-Instruct. \n",
    "SOLAR 10.7B is publicly available under the Apache 2.0 license, \n",
    "promoting broad access and application in the LLM field.\n",
    "\"\"\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Make 3 questions using this text.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "Linear transformation is a function that satisfies two features.\n",
    "One is homogenity, and other is additivity.\n",
    "\n",
    "Linear transformation of the subspace is also subspace.\n",
    "Prove or disprove this statement based on given contents.\n",
    "\"\"\"\n",
    "\n",
    "query3 = \"\"\"\n",
    "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "\n",
      "Context:\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "In this query, separate the instruction and context. Do not answer to the query, just separate it.\n",
    "Context is can be a base information or some text to convert or manipulate.\n",
    "Context can be not provided(N/A for this case).\n",
    "Instruction and context must not have duplicate contents.\n",
    "Print instruction as first paragraph and context as second paragraph.\n",
    "---\n",
    "Query : {query}\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"query\": query3})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the total number of apples the cafeteria has after using some and buying more, follow these steps:\n",
      "\n",
      "1. Determine the initial number of apples the cafeteria had.\n",
      "2. Subtract the number of apples used from the initial number to find out how many are left.\n",
      "3. Add the number of apples bought to the remaining number to find the total number of apples after the purchase.\n",
      "\n",
      "Here's a simple formula to help you calculate this:\n",
      "\n",
      "Total apples = Initial apples - Used apples + Bought apples\n",
      "\n",
      "By following these steps and using the formula, you will be able to calculate the total number of apples the cafeteria has after using some and buying more.\n"
     ]
    }
   ],
   "source": [
    "# answer를 regex로 분리\n",
    "# instruction을 단계로 분리 (LLM 도움)\n",
    "# 각 chain을 실행하고 결과 누적으로 얻음\n",
    "# (전체 히스토리 누적 후) 최종 결과 질문\n",
    "instr = \"Calculate the total number of apples the cafeteria has after using some and buying more.\"\n",
    "context = \"The cafeteria had 23 apples, used 20 to make lunch, and bought 6 more.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "For instruction \"{instr}\", give me what to do to achieve this instruction.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"instr\": instr, \"context\": context})\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
