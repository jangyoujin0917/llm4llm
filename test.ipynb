{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# set UPSTAGE_API_KEY in .env file\n",
    "# UPSTAGE_API_KEY=your_api_key\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, \n",
    "demonstrating superior performance in various natural language processing (NLP) tasks. \n",
    "Inspired by recent efforts to efficiently up-scale LLMs, \n",
    "we present a method for scaling LLMs called depth up-scaling (DUS), \n",
    "which encompasses depthwise scaling and continued pretraining.\n",
    "In contrast to other LLM up-scaling methods that use mixture-of-experts, \n",
    "DUS does not require complex changes to train and inference efficiently. \n",
    "We show experimentally that DUS is simple yet effective \n",
    "in scaling up high-performance LLMs from small ones. \n",
    "Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, \n",
    "a variant fine-tuned for instruction-following capabilities, \n",
    "surpassing Mixtral-8x7B-Instruct. \n",
    "SOLAR 10.7B is publicly available under the Apache 2.0 license, \n",
    "promoting broad access and application in the LLM field.\n",
    "\"\"\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Make 3 questions using this text.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "Linear transformation is a function that satisfies two features.\n",
    "One is homogeneity, and other is additivity.\n",
    "\n",
    "Linear transformation of the subspace is also subspace.\n",
    "Prove or disprove this statement based on given contents.\n",
    "\"\"\"\n",
    "\n",
    "query3 = \"\"\"\n",
    "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "\"\"\"\n",
    "\n",
    "query4 = \"\"\"\n",
    "What is a Mahjong game?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prove or disprove the statement that the linear transformation of the subspace is also a subspace based on the given contents.\n",
      "Linear transformation is a function that satisfies two features. One is homogeneity, and the other is additivity.\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are the AI that separates instruction and context from the user input.\n",
    "In this query, separate the instruction and context.\n",
    "Do not answer to the query, just separate it. Also, only use given query itself, do not generate or change any words.\n",
    "Instruction is saying about what AI should do.\n",
    "Context is can be a base information or some text to convert or manipulate.\n",
    "Context can be not provided(N/A for this case).\n",
    "Instruction and context must not have duplicate contents.\n",
    "Print instruction as first paragraph and context as second paragraph.\n",
    "---\n",
    "Query : {query}\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"query\": query2})\n",
    "\n",
    "instr, context = [s.strip() for s in answer.split(\"Instruction:\")[1].split(\"Context:\")]\n",
    "print(instr)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Understand the definition of a subspace: A subspace of a vector space is a subset of the vector space that is closed under vector addition and scalar multiplication.', '2. Understand the definition of a linear transformation: A linear transformation is a function that preserves the operations of vector addition and scalar multiplication.', '3. Apply the definition of a subspace to the image of the linear transformation: The image of a linear transformation is the set of all output vectors for all input vectors.', '4. Prove or disprove whether the image of the linear transformation is closed under vector addition and scalar multiplication.', '5. If the image is closed under vector addition and scalar multiplication, then the image is a subspace.', '6. If the image is not closed under vector addition or scalar multiplication, then the image is not a subspace.']\n"
     ]
    }
   ],
   "source": [
    "# 각 chain을 실행하고 결과 누적으로 얻음\n",
    "# (전체 히스토리 누적 후) 최종 결과 질문\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "For instruction \"{instr}\", give me what to do to achieve this instruction for AI.\n",
    "Only print 1., 2., 3., ... steps to do. Do not answer to the question, and only print steps.\n",
    "Each step should be a one-liner.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"instr\": instr, \"context\": context}).split(\"\\n\")\n",
    "print(answer)\n",
    "print(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement that the linear transformation of a subspace is also a subspace can be proven based on the given contents. A subspace of a vector space is defined as a subset of the vector space that is closed under vector addition and scalar multiplication.\n",
      "\n",
      "A linear transformation is a function that maps vectors from one vector space to another, preserving the operations of vector addition and scalar multiplication. This means that for any two vectors u and v in the domain vector space, and any scalar c, the following properties hold:\n",
      "\n",
      "1. Homogeneity: T(c * u) = c * T(u)\n",
      "2. Additivity: T(u + v) = T(u) + T(v)\n",
      "\n",
      "Given that the domain of the linear transformation is a subspace, and the transformation preserves the operations of vector addition and scalar multiplication, it follows that the image of the transformation, which is the range of all possible output vectors, will also be closed under these operations.\n",
      "\n",
      "Therefore, the image of a linear transformation, when the domain is a subspace, is itself a subspace of the codomain vector space. This is because the image is closed under vector addition and scalar multiplication, which are the defining properties of a subspace.\n",
      "\n",
      "In summary, the linear transformation of a subspace is indeed a subspace, as the transformation preserves the properties that define a subspace.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "history = []\n",
    "\n",
    "for i in range(len(answer)):\n",
    "    if (i == 0):\n",
    "        history.append(\n",
    "            HumanMessage(answer[i] + \"\\n Refer to or use this context.\\n Context:\" + context)\n",
    "        )\n",
    "    else:\n",
    "        history.append(\n",
    "            HumanMessage(answer[i]) \n",
    "        )\n",
    "    chain_result = chain.invoke({\"history\": history})\n",
    "    history.append(\n",
    "        AIMessage(chain_result)\n",
    "    )\n",
    "\n",
    "history.append(\n",
    "    HumanMessage(instr)\n",
    ")\n",
    "answer = chain_result = chain.invoke({\"history\": history})\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
