{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# set UPSTAGE_API_KEY in .env file\n",
    "# UPSTAGE_API_KEY=your_api_key\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
    "\"\"\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Make a 3 problem in this abstract.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "Linear transformation is a function that satisfies two features.\n",
    "One is homogeneity, and other is additivity.\n",
    "\n",
    "Linear transformation of the subspace is also subspace.\n",
    "Prove or disprove this statement based on given contents.\n",
    "\"\"\"\n",
    "\n",
    "query3 = \"\"\"\n",
    "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "\"\"\"\n",
    "\n",
    "query4 = \"\"\"\n",
    "What is a Von Neumman structure?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prove or disprove the statement \"Linear transformation of the subspace is also subspace\" based on the given contents.\n",
      "Linear transformation is a function that satisfies two features. One is homogeneity, and other is additivity.\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "message = query2\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are the AI that separates instruction and context from the query.\n",
    "In this query, separate the instruction and context. Instruction and context must not have duplicate contents.\n",
    "Only use given query itself, do not generate or change any words from the query.\n",
    "Instruction is saying about what AI should do.\n",
    "Context is can be a base information or some text to convert or manipulate.\n",
    "Context can be not provided, then print context to not provided. Do not make context.\n",
    "Print instruction as first paragraph and context as second paragraph.\n",
    "---\n",
    "Query : {query}\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"query\": message})\n",
    "\n",
    "instr, context = [s.strip() for s in answer.split(\"Instruction:\")[1].split(\"Context:\")]\n",
    "print(instr)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Recall the definition of a linear transformation.', '2. Define what a subspace is.', '3. Apply the definition of a linear transformation to a subspace.', '4. Determine if the result of the linear transformation is still a subspace.', '5. Provide a proof or counterexample to support your conclusion.']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tavily import TavilyClient\n",
    "\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "scontext = str(tavily.search(query=instr))\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "For instruction \"{instr}\", divide instruction into few steps.\n",
    "Do not answer or calculate for each steps, and only divide instructions to the smaller problem.\n",
    "Only print 1., 2., 3., ... steps to do. Each step should be a one-liner.\n",
    "Refer to the context if you need : {context}\n",
    "Searched context to help dividing instructions : {scontext}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"instr\": instr, \"context\": context, \"scontext\": scontext}).split(\"\\n\")\n",
    "print(answer)\n",
    "print(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "For instruction \"{instr}\", determine instruction can be done only using context.\n",
    "Just answer it in \"Yes\" or \"No\".\n",
    "---\n",
    "Context : {context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "answer = chain.invoke({\"instr\": instr, \"context\": context})\n",
    "print(answer)\n",
    "\n",
    "add = \"\"\n",
    "\n",
    "if(answer.startswith(\"No\")): # find context from tavily\n",
    "    context = scontext\n",
    "    add = \"\\nAnswer with references if it exists.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement \"Linear transformation of the subspace is also subspace\" is true. This can be proven based on the definition of a linear transformation and a subspace.\n",
      "\n",
      "A linear transformation is a function that satisfies two properties: homogeneity and additivity. Homogeneity means that for any scalar c and vector v in the domain of the transformation, the transformation maps cv to c times the transformation of v. Additivity means that for any two vectors v and w in the domain of the transformation, the transformation maps v + w to the sum of the transformations of v and w.\n",
      "\n",
      "Now, let's consider a linear transformation T applied to a subspace S of a vector space V. Since T is a linear transformation, it preserves both addition and scalar multiplication. This means that for any vectors v and w in S and any scalar c, we have:\n",
      "\n",
      "1. T(v + w) = T(v) + T(w)\n",
      "2. T(cv) = cT(v)\n",
      "\n",
      "Since S is a subspace, it is closed under addition and scalar multiplication. Therefore, T(v + w) and T(cv) will also be in S. As a result, the image of T, which is the set of all possible outputs of T, will also be closed under addition and scalar multiplication. Thus, the image of T is a subspace of the target vector space.\n",
      "\n",
      "In conclusion, the statement \"Linear transformation of the subspace is also subspace\" is true. This can be proven based on the properties of linear transformations and the definition of a subspace.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "history = []\n",
    "\n",
    "for i in range(len(answer)):\n",
    "    if (i == 0 and len(context) != 0):\n",
    "        history.append(\n",
    "            HumanMessage(answer[i] + \"\\n Refer to or use this context.\\n Context:\" + context)\n",
    "        )\n",
    "    else:\n",
    "        history.append(\n",
    "            HumanMessage(answer[i]) \n",
    "        )\n",
    "    chain_result = chain.invoke({\"history\": history})\n",
    "    history.append(\n",
    "        AIMessage(chain_result)\n",
    "    )\n",
    "\n",
    "history.append(\n",
    "    HumanMessage(message + add + \"\\nIf answer is not context-based, then only print 'I don't know about that.'\")\n",
    ")\n",
    "answer = chain_result = chain.invoke({\"history\": history})\n",
    "\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
